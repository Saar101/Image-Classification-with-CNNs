<!-- PROJECT HEADER -->
<h1 align="center">ğŸª¨ğŸ“„âœ‚ï¸ Rockâ€“Paperâ€“Scissors Image Classification with CNNs</h1>

<p align="center">
  A TensorFlow/Keras deep-learning project for classifying hand-gesture images into rock, paper, and scissors.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/TensorFlow-2.20+-orange" alt="TensorFlow">
  <img src="https://img.shields.io/badge/Python-3.10+-blue" alt="Python">
  <img src="https://img.shields.io/badge/License-MIT-green" alt="License">
</p>

---

## ğŸ“š Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Project Structure](#-project-structure)
- [Requirements](#-requirements)
- [Quick Start](#-quick-start)
- [Model Architecture](#-model-architecture)
- [Training Configuration](#-training-configuration)
- [Dataset](#-dataset)
- [Results & Evaluation](#-results--evaluation)
- [Key Code Sections](#-key-code-sections)
- [Customization](#-customization)
- [Dependencies](#-dependencies)
- [Usage Examples](#-usage-examples)
- [Future Enhancements](#-future-enhancements)
- [Author](#-author)
- [References](#-references)

---

## ğŸ“‹ Overview

This repository showcases an end-to-end **image classification pipeline** using a **Convolutional Neural Network (CNN)** to classify hand-gesture images into:

- ğŸª¨ **Rock**  
- ğŸ“„ **Paper**  
- âœ‚ï¸ **Scissors**  
- â• Background class  

The project includes both an interactive **Jupyter Notebook** and a **standalone Python script**, making it suitable for experimentation, learning, and quick reproducible runs.

---

## ğŸ¯ Features

- âœ… **Automated Dataset Download** â€“ Seamless dataset acquisition via the Kaggle API  
- âœ… **Efficient TF.Data Pipeline** â€“ Prefetching, batching, and shuffling for smooth training  
- âœ… **CNN Architecture** â€“ 3Ã— Conv2D + MaxPooling blocks with dropout regularization  
- âœ… **Model Checkpointing** â€“ Automatically saves the best model (validation loss)  
- âœ… **Early Stopping** â€“ Stops training when no improvement is detected  
- âœ… **Error Analysis** â€“ Visualizes misclassified examples for better debugging  
- âœ… **Dual Format** â€“ Jupyter Notebook (`main.ipynb`) + script (`main.pyt`)  

---

## ğŸ“ Project Structure

```bash
Image-Classification-with-CNNs/
â”œâ”€â”€ main.ipynb               # Interactive Jupyter Notebook
â”œâ”€â”€ main.pyt                 # Standalone Python script (full pipeline)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ README.md                # Project documentation
â””â”€â”€ data/
    â”œâ”€â”€ archive.zip          # Dataset (auto-downloaded)
    â””â”€â”€ rps_data/            # Extracted dataset
        â”œâ”€â”€ rock/
        â”œâ”€â”€ paper/
        â””â”€â”€ scissors/
```

> âš ï¸ `archive.zip` is auto-downloaded via Kaggle and can be **.gitignored** in your own fork to avoid large files in Git.

---

## ğŸ”§ Requirements

- **Python**: 3.10+
- **Core Packages**:
  - TensorFlow 2.20+
  - NumPy
  - Matplotlib
  - Kaggle (API)
  - Pillow

Install everything with:

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Quick Start

### â–¶ï¸ Option 1: Run via Jupyter Notebook

```bash
jupyter notebook main.ipynb
```

Then:

1. Run the cells in order.  
2. The notebook will:
   - Download and extract the dataset  
   - Build and compile the CNN  
   - Train the model  
   - Show metrics, plots, and misclassified samples  

---

### ğŸ–¥ï¸ Option 2: Run via Python Script

```bash
python main.pyt
```

This will:

- Download the dataset (if needed)
- Prepare the input pipeline
- Train the model
- Evaluate and save:
  - `best_rps_model.keras`
  - `rps_cnn_final.keras`

---

## ğŸ§  Model Architecture

| Layer         | Configuration                        | Parameters |
|--------------|--------------------------------------|-----------|
| **Input**    | 150Ã—150 RGB images                   | â€“         |
| **Rescaling**| Normalize to [0, 1]                  | â€“         |
| **Conv2D #1**| 32 filters, 3Ã—3 kernel, ReLU         | 896       |
| **MaxPool #1**| 2Ã—2 pool                            | â€“         |
| **Conv2D #2**| 64 filters, 3Ã—3 kernel, ReLU         | 18,496    |
| **MaxPool #2**| 2Ã—2 pool                            | â€“         |
| **Conv2D #3**| 128 filters, 3Ã—3 kernel, ReLU        | 73,856    |
| **MaxPool #3**| 2Ã—2 pool                            | â€“         |
| **Flatten**  | â€“                                    | â€“         |
| **Dense #1** | 128 units, ReLU                      | 131,200   |
| **Dropout**  | 50%                                  | â€“         |
| **Output**   | 4 classes, Softmax                   | 516       |
| **Total**    | â€“                                    | ~225K     |

---

## âš™ï¸ Training Configuration

```python
RUN_FULL_TRAIN = True              # Train for full NUM_EPOCHS
EARLY_STOPPING_PATIENCE = 5        # Stop if no improvement for 5 epochs
NUM_EPOCHS = 30                    # Maximum training epochs
BATCH_SIZE = 32                    # Samples per batch
IMAGE_SIZE = (150, 150)            # Input image resolution
VALIDATION_SPLIT = 0.2             # 80% train, 20% validation
```

- **Optimizer**: Adam (`learning_rate = 0.001`)  
- **Loss Function**: Sparse Categorical Crossentropy  
- **Metric**: Accuracy  

---

## ğŸ“¦ Dataset

This project uses the **Rock-Paper-Scissors** dataset from Kaggle:

- **Source**: [drgfreeman/rockpaperscissors](https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors)  
- **Total Samples**: ~2,500 images  
- **Classes**: `rock`, `paper`, `scissors`, `background`  
- **Original Format**: PNG, ~500Ã—500 px (resized to 150Ã—150)

### ğŸ” Kaggle API Setup

1. Get your `kaggle.json` from your Kaggle account.  
2. Place it in:

   ```text
   ~/.kaggle/kaggle.json
   ```

3. Make sure it has proper permissions if you are on Linux/macOS.

The script/notebook will then handle **downloading and extracting** the dataset automatically.

---

## ğŸ“ˆ Results & Evaluation

During and after training, the project provides:

- ğŸ“‰ **Loss & Accuracy Curves** per epoch (train vs. validation)  
- âœ… **Validation Accuracy** on a held-out subset  
- ğŸ§¯ **Error Analysis**: visualization of misclassified images (up to 6 samples)  
- ğŸ’¾ **Model Artifacts**:
  - `best_rps_model.keras` â€“ Best checkpoint (lowest validation loss)  
  - `rps_cnn_final.keras` â€“ Final model at the end of training  

---

## ğŸ” Key Code Sections

### Data Loading

```python
importer = DataImporter()
data_dir = importer.import_data()  # Auto-downloads & extracts dataset
```

### Model Definition

```python
model = tf.keras.Sequential([
    tf.keras.layers.Rescaling(1./255, input_shape=(150, 150, 3)),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    # ... 2 more Conv + Pool blocks ...
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])
```

### Training

```python
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=NUM_EPOCHS,
    callbacks=callbacks
)
```

---

## ğŸ› ï¸ Customization

**Adjust training behavior:**

- Change `NUM_EPOCHS`, `BATCH_SIZE`, `IMAGE_SIZE`  
- Modify architecture: add more `Conv2D`, `Dense`, or `Dropout` layers  
- Tune `EARLY_STOPPING_PATIENCE` or optimizer settings  

**Ideas to improve performance:**

- ğŸ“ˆ Add data augmentation (rotation, flipping, zoom, brightness)  
- ğŸ–¼ï¸ Increase input resolution (e.g. 200Ã—200, 224Ã—224)  
- ğŸ§¬ Use transfer learning (ResNet, MobileNet, etc.)  
- âš–ï¸ Use class weights if classes are imbalanced  

---

## ğŸ“š Dependencies

See `requirements.txt` for the complete list. Key versions:

```text
tensorflow==2.20.0
numpy>=1.24.0
matplotlib>=3.6.0
kaggle>=1.5.12
Pillow>=9.0.0
```

---

## ğŸ“ Usage Examples

### ğŸ” Train the model via script

```bash
python main.pyt
```

### ğŸ““ Run interactively in Jupyter

```bash
jupyter notebook main.ipynb
```

### ğŸ”® Load a saved model and predict

```python
import tensorflow as tf

model = tf.keras.models.load_model('rps_cnn_final.keras')
predictions = model.predict(new_images)  # new_images should be preprocessed
```

---

## ğŸš§ Future Enhancements

- [ ] Data augmentation pipeline (rotation, brightness, zoom)  
- [ ] Transfer learning with pre-trained backbones (ResNet50, MobileNetV2)  
- [ ] TensorBoard integration for real-time monitoring  
- [ ] Confusion matrix and classification report  
- [ ] Flask / FastAPI web service for inference  
- [ ] Model quantization for mobile deployment  
- [ ] Automated hyperparameter tuning (Keras Tuner)  

---

## ğŸ‘¤ Author

Developed as an educational **deep learning** exercise focused on end-to-end CNN-based image classification and practical ML workflows.

---

## ğŸ”— References

- [TensorFlow Documentation](https://www.tensorflow.org)  
- [Keras Sequential API](https://keras.io/api/models/sequential/)  
- [Kaggle Datasets](https://www.kaggle.com/datasets)  

---

> **Last Updated**: December 2025
